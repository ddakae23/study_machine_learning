# -*- coding: utf-8 -*-
"""exam06_titanic.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tcQXHbixrLTwbN53fI7Hput09yy7s7XG

##타이타닉 이진분류기
"""

import pandas as pd
import numpy as np
import seaborn as sns
from sklearn import preprocessing

pd.set_option('display.max_columns',8)
pd.set_option('display.unicode.east_asian', True) #한글 줄맞춤할때 사용하는 함수

df = sns.load_dataset('titanic')
print(df.head(20))

df.info()

nan_deck = df['deck'].value_counts(dropna = False)
print(nan_deck)

print(df.head().isnull())   #null이면 True

print(df.head().notnull())

print(df.isnull().sum())    #null값 총 갯수

df.dropna(axis=1, thresh=500, inplace=True) # NaN 값이 500개 이상이면 그 콜론을 지워라!// deck콜론 제거
print(df.columns)

df_age = df.dropna(subset=['age'],how='any',axis=0) #age가 NaN값이 아닌 콜론만 남김
df_age.info()                                       #df원본은 남겨져있음

mean_age = df['age'].mean()
df['age'].fillna(mean_age, inplace = True)
print(df.head(10))

most_freq = df['embark_town'].value_counts(dropna=True).idxmax()    ##idxmax()함수는 가장 큰값의 인덱스 값 출력
print(most_freq)                                                    ##인덱스맥스함수 사용안하면 전체 인덱스 값출력됨

df_most_freq = df['embark_town'].fillna(most_freq, inplace=False)
print(df_most_freq[825:830])
print(df[825:830])

df_most_freq = df['embark_town'].fillna(method='ffill', inplace=True)   ##ffill사용으로 NaN값을 위와 같은 값으로 변경
print(df[825:830])                                                      # inplace=True / inplace는 변경할지 여부 확인하는 메서드 True면 변경하는것

df.info()

df.drop(['alive','embarked'], axis=1, inplace=True)  # alive,embarked 제거함
df.info()

target = df[['survived']]
target

training_data = df.drop(['survived'], axis=1)
training_data.columns

training_data.info()

value_data = training_data[['age','fare']]
print(value_data.columns)

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaled_data = scaler.fit_transform(value_data)
value_data = pd.DataFrame(scaled_data, columns=value_data.columns)
print(value_data.head())

training_data.drop(['age','fare'], axis=1, inplace=True)
print(training_data.head())

onehot_data = pd.get_dummies(training_data, columns=training_data.columns, dtype=float)
onehot_data.info()

training_data = pd.concat([value_data, onehot_data],axis=1)
training_data.info()

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(
    training_data, target, test_size=0.2)

print(X_train.shape)
print(Y_train.shape)
print(X_test.shape)
print(Y_test.shape)

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout

model = Sequential()
model.add(Dense(128, input_dim=34, activation = 'relu'))
model.add(Dropout(0.02))
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.02))
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.02))
model.add(Dense(256, activation='relu'))
model.add(Dropout(0.02))
model.add(Dense(128, activation='relu'))
model.add(Dropout(0.02))
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.02))
model.add(Dense(32, activation='relu'))
model.add(Dropout(0.02))
model.add(Dense(1,activation='sigmoid'))
model.summary()

model.compile(loss='mse', optimizer='adam', metrics=['binary_accuracy'])
fit_hist = model.fit(X_train, Y_train,
                     batch_size = 50, epochs = 30,
                     validation_split=0.2, verbose=1)

import matplotlib.pyplot as plt
plt.plot(fit_hist.history['binary_accuracy'])
plt.plot(fit_hist.history['val_binary_accuracy'])
plt.show()

score = model.evaluate(X_test, Y_test, verbose=0)
print('loss', score[0])
print('accuracy', score[1])

