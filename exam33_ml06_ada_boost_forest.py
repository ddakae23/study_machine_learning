# -*- coding: utf-8 -*-
"""exam33_ml06_ADA_boost_forest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JlvoByWngCSXauLYlaZifI4yp6NApAwl
"""

import numpy as np
import pandas as pd
from sklearn.datasets import load_iris
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, StratifiedShuffleSplit, GridSearchCV
import matplotlib.pyplot as plt
from sklearn.metrics import *
from sklearn.ensemble import AdaBoostClassifier

iris_dataset = load_iris()
iris = pd.DataFrame(iris_dataset.data, columns=iris_dataset.feature_names)
labels = iris_dataset.target_names
iris.info()
iris.head()

label = iris_dataset.target
label

x_train, x_test, y_train, y_test = train_test_split(iris, label, test_size=0.2, random_state=1)
print(x_train.shape, x_test.shape)
print(y_train.shape, y_test.shape)

n_estimators = [50, 100, 150, 200, 250, 300, 350, 400, 450, 500]
learning_rate = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
algorithm = ['SAMME', 'SAMME.R']
param = {'n_estimators':n_estimators, 'learning_rate':learning_rate, 'algorithm':algorithm}
cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=888)
iris_adaB = GridSearchCV(estimator=AdaBoostClassifier(), param_grid=param,
                         scoring='accuracy', n_jobs=-1, cv=cv)
iris_adaB.fit(x_train, y_train)

print(iris_adaB.best_score_)
print(iris_adaB.best_params_)
print(iris_adaB.best_estimator_)

learning_rate = [0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25]
algorithm = ['SAMME', 'SAMME.R']
param = {'learning_rate':learning_rate, 'algorithm':algorithm}
cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=888)
iris_adaB = GridSearchCV(estimator=AdaBoostClassifier(n_estimators=50), param_grid=param,
                         scoring='accuracy', n_jobs=-1, cv=cv)
iris_adaB.fit(x_train, y_train)

print(iris_adaB.best_score_)
print(iris_adaB.best_params_)
print(iris_adaB.best_estimator_)

for i in range(100):
    x_train, x_test, y_train, y_test = train_test_split(iris, label, test_size=0.2, random_state=i)
    iris_adaboosting = iris_adaB.best_estimator_
    iris_adaboosting.fit(x_train, y_train)
    train_score = iris_adaboosting.score(x_train, y_train)
    test_score = iris_adaboosting.score(x_test, y_test)
    if test_score >= train_score:
        print(test_score, train_score, i)

x_train, x_test, y_train, y_test = train_test_split(iris, label, test_size=0.2, random_state=3)
iris_adaboosting = iris_adaB.best_estimator_
iris_adaboosting.fit(x_train, y_train)
train_score = iris_adaboosting.score(x_train, y_train)
test_score = iris_adaboosting.score(x_test, y_test)
print(test_score, train_score)

pd.DataFrame(confusion_matrix(y_test, iris_adaboosting.predict(x_test)),
             columns=['pred setosa', 'pred versicolore', 'pred_virginica'],
             index=['actual setosa', 'actual versicolore', 'actual virginica'])

